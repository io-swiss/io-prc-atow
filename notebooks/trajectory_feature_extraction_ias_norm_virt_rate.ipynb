{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91dda2-353d-4a5d-a054-2cfbfb90bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af8ba3-1c87-4fc7-93df-ce962f64a63e",
   "metadata": {},
   "source": [
    "# Load Challenge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b4a2cd-e4e9-49ee-a57e-2bc789336fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_data = pd.read_csv(\"../data/challenge_set.csv\")\n",
    "submission_data = pd.read_csv(\"../data/final_submission_set.csv\")\n",
    "print(f\"{challenge_data.shape[0]=}, {submission_data.shape[0]=}\")\n",
    "challenge_data = pd.concat([challenge_data, submission_data], axis=0)\n",
    "challenge_data.reset_index(drop=True, inplace=True)\n",
    "print(f\"{challenge_data.shape[0]=}\")\n",
    "challenge_data['takeoff_time'] = pd.to_datetime(challenge_data['actual_offblock_time'], utc=True) + pd.to_timedelta(challenge_data['taxiout_time'], unit='m')\n",
    "challenge_data['arrival_time'] = pd.to_datetime(challenge_data['arrival_time'], utc=True)\n",
    "print(challenge_data.dtypes)\n",
    "print(f\"{challenge_data[['flight_id']].drop_duplicates().shape[0]=}\")\n",
    "challenge_data[['flight_id','date','actual_offblock_time','taxiout_time','takeoff_time','arrival_time','flight_duration','flown_distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd8f5bc-f2a8-48c5-b624-dc61d91e65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_data = challenge_data[['flight_id', \"takeoff_time\", \"arrival_time\"]]\n",
    "challenge_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd4c7a-4e59-46a4-a38e-3bdf1bd0effa",
   "metadata": {},
   "source": [
    "# Load _ALL_ `parquet` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a9764-818a-43ed-90b1-bbb03cc6937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "input_dir = Path(\"../data/\")\n",
    "output_dir = iPath(\"../data_cleaned/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# List all .parquet files in the input directory\n",
    "parquet_files = glob.glob(str(input_dir / \"*.parquet\"))\n",
    "\n",
    "# Function to process each file\n",
    "def process_file(file):\n",
    "    # Load file using pyarrow engine for faster reads\n",
    "    df = pd.read_parquet(file, engine='pyarrow')\n",
    "\n",
    "    # Sort and merge as before\n",
    "    df.sort_values([\"flight_id\", \"timestamp\"], inplace=True)\n",
    "    df = df.merge(challenge_data, on='flight_id', how='inner')\n",
    "\n",
    "    # Filter based on timestamp conditions\n",
    "    df = df[(df.timestamp >= df.takeoff_time) & \n",
    "            (df.timestamp <= df.takeoff_time + (df.arrival_time - df.takeoff_time) / 2)]\n",
    "\n",
    "    # Select relevant columns\n",
    "    df = df[['flight_id', 'timestamp', 'temperature', 'altitude', 'groundspeed', 'vertical_rate']]\n",
    "    \n",
    "    # Save the processed DataFrame to the output directory\n",
    "    output_file = output_dir / os.path.basename(file)\n",
    "    df.to_parquet(output_file, engine='pyarrow')\n",
    "    \n",
    "    print(f\"Converted {file=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211fc65-0f11-40ea-a370-92e0d35fbfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ThreadPoolExecutor for parallel processing\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(process_file, parquet_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0d14f-d071-4982-b7c2-5deddbd81702",
   "metadata": {},
   "source": [
    "# Clean Flight data\n",
    "\n",
    "### Ref: [Trajectory](https://ansperformance.eu/study/data-challenge/data.html#trajectory)\n",
    "> Trajectories are not necessarily complete/overlapping with respect to what reported in the flight list in actual_offblock_time or arrival_time. This is due to the possibly limited/partial ADS-B coverage in some parts (or some lower altitudes) of the world. The interval [actual_offblock_time + taxiout_time, arrival_time] is a good approximation of the in-the-air portion of the flight.\n",
    "\n",
    "### Ref: [Exploratory Data Analysis](https://ansperformance.eu/study/data-challenge/data.html#using-traffic-for-exploratory-data-analysis)\n",
    "> Consider only the `[actual_offblock_time + taxiout_time, arrival_time]` interval for the in-the-air portion of the flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cad09b-fd8c-4e5c-8243-fdaced91a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_ddf0.columns = ['_'.join(col).strip() for col in aggregated_ddf0.columns.values]\n",
    "aggregated_ddf0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079f063-d545-428b-9fda-46af7f909eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_ddf0.to_csv('../data/vertical_rate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085dcad7-2946-4d66-a5ea-ba1039a43fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns you want to aggregate\n",
    "columns_to_aggregate = [\n",
    "    'altitude', 'groundspeed', 'track', 'vertical_rate', \n",
    "    'u_component_of_wind', 'v_component_of_wind', \n",
    "    'temperature', 'specific_humidity'\n",
    "]\n",
    "\n",
    "# Perform the groupby operation and aggregate per flight_id\n",
    "aggregated_ddf = filtered_ddf.groupby('flight_id')[columns_to_aggregate].agg(agg_functions)\n",
    "\n",
    "# Compute the result (this step triggers the actual computation)\n",
    "aggregated_ddf = aggregated_ddf.compute()\n",
    "\n",
    "# Display the first few rows to check the output\n",
    "aggregated_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a2ace-e603-4866-a18d-1463fcb8ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_ddf.columns = ['_'.join(col).strip() for col in aggregated_ddf.columns.values]\n",
    "aggregated_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5c661-c500-47d1-bc1b-34c715440b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_ddf.to_csv('../data/additional_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47277ae-7902-4dc7-ab1d-fe0c583b5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_ratio_sqrt = np.array([1, 0.985, 0.971, 0.956, 0.942, 0.928, 0.914, 0.900, 0.886, 0.873, 0.859, 0.793, 0.730, 0.670, 0.612, 0.556, 0.496, 0.440, 0.390])\n",
    "altitude_ft = np.array([0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000])\n",
    "\n",
    "# Density altitude\n",
    "filtered_ddf['temperature'] = filtered_ddf['temperature'].bfill()\n",
    "filtered_ddf['temperature_celsius'] = filtered_ddf['temperature'] - 273.15\n",
    "filtered_ddf['standard_temp_at_alt'] = 15 - (2 * (filtered_ddf['altitude'] / 1000))\n",
    "filtered_ddf['density_altitude'] = filtered_ddf['altitude'] + 120 * (filtered_ddf['temperature_celsius'] - filtered_ddf['standard_temp_at_alt'])\n",
    "\n",
    "filtered_ddf['density_ratio_sqrt'] = np.interp(filtered_ddf.density_altitude, altitude_ft, density_ratio_sqrt)\n",
    "filtered_ddf['ias'] = filtered_ddf.groundspeed * filtered_ddf.density_ratio_sqrt\n",
    "filtered_ddf['d_ias'] = (\n",
    "    (filtered_ddf.groupby('flight_id')['ias'].shift(-2) - filtered_ddf.groupby('flight_id')['ias'].shift(2))\n",
    "    /\n",
    "    (filtered_ddf.groupby('flight_id')['timestamp'].shift(-2) - filtered_ddf.groupby('flight_id')['timestamp'].shift(2)).dt.total_seconds()\n",
    ")\n",
    "filtered_ddf[\"norm_vertical_rate\"] = ((1 / filtered_ddf.density_ratio_sqrt) ** 2) * (filtered_ddf.vertical_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7db74b-3604-48e0-8a9d-38f15ef51f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ddf[\"condition\"] = (filtered_ddf.vertical_rate > 500) & (filtered_ddf.ias > 250) & (filtered_ddf.d_ias < 0.5)\n",
    "filtered_ddf['group'] = (filtered_ddf['condition'] != filtered_ddf['condition'].shift()).cumsum()\n",
    "filtered_ddf = (\n",
    "    filtered_ddf[filtered_ddf['condition']]  # Keep only rows where condition is True\n",
    "    .groupby('group')  # Group by consecutive blocks\n",
    "    .filter(lambda x: (x['timestamp'].max() - x['timestamp'].min()).total_seconds() >= 5 * 60)  # Duration check\n",
    ")\n",
    "filtered_ddf = filtered_ddf.drop(columns=['temperature_celsius', 'standard_temp_at_alt', 'density_ratio_sqrt', 'd_ias', 'condition', 'group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aac69a9-7071-4cf3-b491-7d6a31d930fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns you want to aggregate\n",
    "columns_to_aggregate = ['norm_vertical_rate', 'ias']\n",
    "\n",
    "# Perform the groupby operation and aggregate per flight_id\n",
    "aggregated_ddf = filtered_ddf.groupby('flight_id')[columns_to_aggregate].agg(agg_functions)\n",
    "\n",
    "# Compute the result (this step triggers the actual computation)\n",
    "aggregated_ddf = aggregated_ddf.compute()\n",
    "\n",
    "# Display the first few rows to check the output\n",
    "aggregated_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33049627-7efd-4e00-b7d8-f1ad15ebad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_ddf.columns = ['_'.join(col).strip() for col in aggregated_ddf.columns.values]\n",
    "aggregated_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d7d884-21a7-40e7-90a1-86b52170809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_ddf.to_csv('../data/ias_norm_virt_rate.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
